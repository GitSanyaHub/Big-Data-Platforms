## 3. Установка и настройка Apache Hive

### Подготовка окружения

Полключаемся по ssh:
```bash
ssh team@176.109.91.8
```

Вводим пароль и попадаем в jn. Переключимся в пользователя Hadoop:

```bash
sudo -i -u hadoop
```

Для начала установим Hive, скачав архив с официального сайта Apache:

```bash
wget https://dlcdn.apache.org/hive/hive-4.0.1/apache-hive-4.0.1-bin.tar.gz
```

Распакуем архив:

```bash
tar -xzvf apache-hive-4.0.1-bin.tar.gz
```

Зайдем внутрь
```bash
cd apache-hive-4.0.1-bin
```

### Настройка Hadoop
Откроем файл ~/.profile для настройки окружения:


```bash
vim ~/.profile
```

Добавим следующие строки в конец файла и сохраним изменения:

```bash
export HADOOP_HOME=/home/hadoop/hadoop-3.4.0
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

Активируем новые переменные окружения:

```bash
source ~/.profile
```

Проверим установку Hadoop:

```bash
hadoop version
```

### Настройка Hive

Добавим переменную HIVE_HOME и обновим PATH:

```bash
export HIVE_HOME=/home/hadoop/apache-hive-4.0.1-bin
export PATH=$HIVE_HOME/bin:$PATH
```
Создадим конфигурационный файл hive-site.xml и папки 

```bash
vim conf/hive-site.xml
```
Cоздадим папочки для хранения данных Hive:
```bash
hdfs dfs -ls /
cd ../hadoop-3.4.0/
export
hdfs dfs -ls
```
Подключимся для этого пока к нашей нейм ноде и создадим эти папочки:
```bash
ssh team-6-nn
hdfs dfs -ls
```
Создадим папочку и дадим некоторые права на нее и временную папку /tmp
```bash
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod g+w /tmp
hdfs dfs -chmod g+w /user/hive/warehouse
```
Перейдем обратно на jn ноду:
```
exit
```
Перейдём в директорию конфигурации Hive:
```bash
cd ../apache-hive-4.0.1-bin/conf
```
Скопируем шаблонный файл конфигурации:
```bash
ср hive-default.xml.template hive-site.xml 
```

Посмотрим какие папки есть в директории
```bash
ls -lh
```

### Конфигурация для хранения данных Hive

Добавим следующую настройку в hive-site.xml для указания директории хранения данных:

```bash
vim hive-site.xml
```

```xml
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description> Defines the rewrite policy, the valid values are those defined in RewritePolicy enum <description> 
</property>
```

Скопируем и настроим hive-env.sh:

```bash
cp hive-env.sh.template hive-env.sh
```

Добавим переменные окружения для Hive:

```bash
vim hive-env.sh
```

```bash
# export HADOOP_HOME=/home/hadoop/hadoop-3.4.0
# export JAVA_HOME=/us/lib/jvm/java-11-openjdk-amd64
export HIVE_HOME=/home/hadoop/apache-hive-4.0.1-bin
export HIVE_CONF_DIR=SHIVE_HOME/conf
export HIVE_AUX_JARS_PATH=SHIVE_HOME/lib/*
```
### Установка PostgreSQL

Переключимся на nn и установим PostgreSQL:

```bash
ssh tmpl-nn
```
Установим постгрес:
 ```bash
sudo apt install postgresql postgresql-contrib
```
Проверим, что он работает:
```bash
sudo systemctl status postgresql
```
Переключимся в пользователя PostgreSQL для создания базы данных:

```bash
sudo -i -u postgres
psql
```
Создадим базу данных и пользователя для Hive:


```sql
CREATE DATABASE metastore ;
CREATE USER hive with password 'hive';
```

Дадим ему права на эту базу данных 
``` sql
GRANT ALL PRIVILEGES ON DATABASE "metastore" to hive;
ALTER DATABASE metastore OWNER TO hive;
```

Выйдем из PostgreSQL:

```bash
\q
exit
```

Настроим файл конфигурации для доступа с нужных хостов:

```bash
vim /etc/postgresql/16/main/pg_hba.conf
```
Добавим следующую строку:

```bash
# IPv4 local connections:

host    all     all     127.0.0.1/32    scram-sha-256
host    all     all     192.168.1.2     trust
```

Перезапустим PostgreSQL:

```bash
sudo systemctl restart postgresql
```
Проверим статус:
```bash
sudo systemctl status postgresql
```

### Завершающая настройка Hive

Вернемся на jn, установим PostgreSQL драйвер для Hive:
```
exit
```

Оказавшись здесь team@team-6-jn:
```bash
cd apache-hive-4.0.1-bin/conf/
source hive-env.sh
export
```

Установим PostgreSQL драйвер для Hive:

```bash
cd /home/hadoop/apache-hive-4.0.1-bin/lib/
wget https://jdbc.postgresql.org/download/postgresql-42.7.4.jar
```

Драйвер есть, теперь нужно прописать к нему доступы
```bash
cd ../conf
vim hive-site.xml    
```

Настроим подключение Hive к PostgreSQL:

```xml
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:postgresql://192.168.1.3:5432/metastore</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.postgresql.Driver</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
</property>
```
Перейдем:
```bash
cd ../
```
Инициализируем схему Hive:

```bash
bin/schematool -dbType postgresql -initschema
```

## Вывод
Мы успешно установили и настроили Apache Hive для работы с базой данных PostgreSQL. Теперь Hive может использовать PostgreSQL в качестве метастора для хранения метаданных и обрабатывать данные, хранящиеся в HDFS. Эта настройка позволяет эффективно управлять данными и использовать преимущества распределённой обработки Hive.

