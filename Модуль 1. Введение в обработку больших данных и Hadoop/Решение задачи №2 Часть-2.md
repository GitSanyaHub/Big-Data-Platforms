## Предусловия


- Узлы кластера уже должны быть связаны между собой по ssh
- Для старта мы уже должны находиться на *nn* из-под пользователя *hadoop*
- Перед началом нужно убедиться, что версии Hadoop и Java совместимы

```
hadoop@team-6-nn:~$ java --version
```
## 1. Зададим JAVA_HOME, HADOOP_HOME и PATH
### 1.1 Получаем путь до Java

```
hadoop@team-6-nn:~$ which java
```

- Вставим ответ предыдущей команды в следующую для получения полного пути

```
hadoop@team-6-nn:~$ readlink -f /usr/bin/java
```

- Путь, который показывает, где установлен Java, будет иметь следующий вид
```
/usr/lib/jvm/java-11-openjdk-amd64/bin/java
```

### 1.2 Получаем путь до Hadoop

- Зайдем в директорию с Hadoop
```
hadoop@team-6-nn:~$ cd hadoop-3.4.0/
```

- Получим путь
```
hadoop@team-6-nn:~/hadoop-3.4.0$ pwd
```

- Результат имеет вид
```
/home/hadoop/hadoop-3.4.0
```
### 1.3 Добавляем JAVA_HOME, HADOOP_HOME и PATH в `~/.profile`
- Выйдем из папки с Hadoop
```
hadoop@team-6-nn:~/hadoop-3.4.0$ cd ..
```
- Откроем файл
```
hadoop@team-6-nn:~$ vim ~/.profile
```

- Сделаем вставку в конце файла и сохраним изменения
```
export HADOOP_HOME=/home/hadoop/hadoop-3.4.0
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

- Сделаем активацию новых переменных

```
hadoop@team-6-nn:~$ source ~/.profile
```

- Сделаем проверку, pезультат должен показать версию Hadoop
```
hadoop@team-6-nn:~$ hadoop version
```

- Создадим копии `~/.profile` на `dn-00` и `dn-01` нодах

```
hadoop@team-6-nn:~$ scp ~/.profile  team-6-dn-01:/home/hadoop
```
```
hadoop@team-6-nn:~$ scp ~/.profile  team-6-dn-00:/home/hadoop
```
### 1.4 Сделаем дополнительное объявление JAVA_HOME в файле `hadoop-env.sh`

- Заходим в папку дистрибутива

```
hadoop@team-6-nn:~$ cd hadoop-3.4.0/etc/hadoop
```

- Изменим конфигурационный скрипт, используемый для настройки переменных окружения 

```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ vim hadoop-env.sh
```
- На следующей строчке после `#  JAVA_HOME=/usr/java/testing hdfs dfs -ls` добавляем

```
JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

- Делаем копии этого файла на другие две ноды

```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp hadoop-env.sh  team-6-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp hadoop-env.sh  team-6-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop
```

## 2. Редактируем конфигурационные файлы кластера

### 2.1 Укажем основной адрес, по которому доступна файловая система

- Откроем файл `core-site.xml` 
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ vim core-site.xml 
```

- Делаем изменения: указываем адрес nn и порт 
```
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://team-6-nn:9000</value>
        </property>
</configuration>
```

### 2.2 Укажем количество реплекаций

- Открываем файл `hdfs-site.xml`
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ vim hdfs-site.xml 
```
- Указываем количество равное трём, так как у нас три ноды
```
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
</configuration>
```

### 2.3 Укажем ноды нашего кластера
- Откроем файл `workers`
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ vim workers 
```
- Убираем `localhost` и вставляем имена наших нод
```
team-6-nn
team-6-dn-00
team-6-dn-01
```

### 2.4 Делаем копии этих трёх файлов после редактивания на две другие ноды

```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp core-site.xml  team-6-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp core-site.xml  team-6-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp hdfs-site.xml  team-6-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp hdfs-site.xml  team-6-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp workers  team-6-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
```
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ scp workers  team-6-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop
```

- Переходим в директорию с hadoop
```
hadoop@team-6-nn:~/hadoop-3.4.0/etc/hadoop$ cd ../..
```

- Форматируем файловую систему

```
hadoop@team-6-nn:~/hadoop-3.4.0$ bin/hdfs namenode -format
```
## 3. Запуск кластера

- Стартуем кластер
```
hadoop@team-6-nn:~/hadoop-3.4.0$ sbin/start-dfs.sh
```
- Проверяем, что доступны `NameNode` и `SecondaryNameNode`
```
hadoop@team-6-nn:~/hadoop-3.4.0$ jps
```
- Переходим на `dn-00` и проверяем, что доступна `DataNode`
```
hadoop@team-6-nn:~/hadoop-3.4.0$ ssh team-6-dn-00
```
```
hadoop@team-6-dn-00:~$ jps
```
```
hadoop@team-6-dn-00:~$ exit
```

- Переходим на `dn-01` и проверяем, что доступна `DataNode`
```
hadoop@team-6-nn:~/hadoop-3.4.0$ ssh team-6-dn-01
```
```
hadoop@team-6-dn-01:~$ jps
```
```
hadoop@team-6-dn-01:~$ exit
```

## 4. Настройка web интерфейса

- Для выполнения следующих шагов мы должны находиться на `jn` вне пользователя `hadoop`: `team@team-6-jn:~$ `

### 4.1 Настройка конфига для `nginx`

- Делаем копию файла
```
team@team-6-jn:~$ sudo cp /etc/nginx/sites-available/default /etc/nginx/sites-available/nn
```
- Откроем файл для редактирования
```
team@team-6-jn:~$ sudo vim /etc/nginx/sites-available/nn
```
- Внесем изменения в файл в разделе `Default server configuration`
1) Указываем порт `9870` в строке `listen 80 default_server;`, чтобы слушать его, потому что `nn` опубликована на хосте `nn`, на порту `9870`
2) Комментируем строку: `listen [::]:80 default_server;`
3) Комментируем строку `try_files $uri $uri/ =404;`, добавляем сразу после этого `proxy_pass http://team-6-nn:9870;`, чтобы перенаправить трафик

- Активируем новую конфигурацию в nginx
```
team@team-6-jn:~$ sudo ln -s /etc/nginx/sites-available/nn /etc/nginx/sites-enabled/nn
```
- Делаем перезагрузку
```
team@team-6-jn:~$ sudo systemctl reload nginx
```
### 4.2 Переходим на сайт для проверки, что все три ноды доступны (см. файлы)
```
http://176.109.91.8:9870
```

## Вывод
В результате работы был настроен кластер Hadoop с поддержкой веб интефейса


